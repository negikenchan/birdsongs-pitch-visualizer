# ============================================
#  ğŸ¦ BirdApp - é³¥ã®ã•ãˆãšã‚Šãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼
#  é–‹ç™ºè€…: æ ¹å²¸å¥å¤ªéƒ (Tomiya High School)
#  åˆç‰ˆ: 2025å¹´7æœˆ19æ—¥
# ============================================
#        ï¼ï¼ã€€ ãƒ•
#        | ã€€_ã€€_| 
#      ï¼` ãƒŸï¼¿xãƒ 
#     /ã€€ã€€ã€€ã€€ |
#    /ã€€ ãƒ½ã€€ã€€ ï¾‰
#    â”‚ã€€ã€€|ã€€|ã€€|
# ï¼ï¿£|ã€€ã€€ |ã€€|ã€€|
# | (ï¿£ãƒ½ï¼¿_ãƒ½_)__)
# ï¼¼äºŒã¤
# ============================================
# 

import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import scipy.io.wavfile as wavfile
from scipy.signal import butter, lfilter
from midiutil import MIDIFile
import io, zipfile, datetime

# ========= åŸºæœ¬é–¢æ•° ========= #
def butter_bandpass(lowcut, highcut, fs, order=5):
    nyq = 0.5 * fs
    low, high = lowcut / nyq, highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    return b, a

def bandpass_filter(data, lowcut, highcut, fs, order=5):
    b, a = butter_bandpass(lowcut, highcut, fs, order)
    return lfilter(b, a, data)

def moving_average(arr, w):
    ret = np.copy(arr)
    for i in range(len(arr)):
        start = max(0, i - w//2)
        end = min(len(arr), i + w//2)
        valid = arr[start:end][~np.isnan(arr[start:end])]
        ret[i] = np.nan if len(valid) == 0 else np.mean(valid)
    return ret

def freq_to_midi(freq):
    return 69 + 12 * np.log2(freq / 440.0)

def midi_to_note_name(midi_num):
    note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
    octave = int(midi_num // 12) - 1
    name = note_names[int(midi_num % 12)]
    return f"{name}{octave}"

def generate_wav_from_midi(freqs, bins, time_per_bin, rate):
    total_duration = bins[-1] + time_per_bin
    t = np.linspace(0, total_duration, int(rate * total_duration))
    signal = np.zeros_like(t)
    for i, freq in enumerate(freqs):
        if np.isnan(freq): continue
        start = int(bins[i] * rate)
        end = int((bins[i] + time_per_bin) * rate)
        end = min(len(t), end)
        signal[start:end] += 0.5 * np.sin(2 * np.pi * freq * t[start:end])
    if np.max(np.abs(signal)) > 0:
        signal /= np.max(np.abs(signal))
    return np.int16(signal * 32767)

st.title("é³¥ã®ã•ãˆãšã‚Šãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼ğŸµï¼ˆMIDIä»˜ãï¼‹ä¸€æ‹¬ä¿å­˜ï¼‰")

uploaded_file = st.file_uploader("WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["wav"])
if uploaded_file:
    rate, data = wavfile.read(uploaded_file)
    if len(data.shape) > 1:
        data = data[:, 0]

    duration = len(data) / rate
    time = np.linspace(0., duration, len(data))
    st.audio(uploaded_file, format="audio/wav")

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å…¥åŠ›
    st.markdown("### ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿")
    dt_now = datetime.datetime.now().strftime("%Y%m%d_%H%M")
    location = st.text_input("å ´æ‰€", "Sendai")
    species = st.text_input("é³¥ã®ç¨®é¡", "unknown")
    situation = st.text_input("çŠ¶æ³", "dawn")

    base_filename = f"{dt_now}_{location}_{species}_{situation}"

    # ãƒ•ã‚£ãƒ«ã‚¿ãªã©ã®è¨­å®š
    lowcut = st.slider("Low Cut (Hz)", 0, rate // 2, 5000)
    highcut = st.slider("High Cut (Hz)", 0, rate // 2, 7000)
    t_range = st.slider("è¡¨ç¤ºç¯„å›²ï¼ˆç§’ï¼‰", 0.0, duration, (0.0, duration), step=0.1)
    cmap = st.selectbox("ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—", ['gray', 'bone', 'cividis', 'viridis', 'plasma', 'magma', 'inferno','monochrome'])
    threshold_ratio = st.slider("æŒ¯å¹…ã—ãã„å€¤ï¼ˆå¹³å‡ã®å€ç‡ï¼‰", 0.0, 2.0, 0.3, 0.05)
    smoothing_sec = st.slider("å¹³æ»‘åŒ–ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆç§’ï¼‰", 0.01, 5.0, 0.5, step=0.01)

    start_idx, end_idx = int(t_range[0] * rate), int(t_range[1] * rate)
    scoped_data = data[start_idx:end_idx]

    filtered = bandpass_filter(scoped_data, lowcut, highcut, rate)
    filtered /= np.max(np.abs(filtered))
    filtered_int16 = np.int16(filtered * 32767)

    time_f = np.linspace(0., len(filtered_int16)/rate, len(filtered_int16))

    fig, ax = plt.subplots(2, 1, figsize=(12, 6), sharex=True)
    ax[0].plot(time, data)
    ax[0].set_title("Original Waveform")
    if cmap == 'monochrome':
        ax[1].specgram(data, Fs=rate, NFFT=1024, noverlap=512, cmap='gray')
    else :
        ax[1].specgram(data, Fs=rate, NFFT=1024, noverlap=512, cmap=cmap)
    ax[1].axhline(lowcut, color='red', linestyle='--')
    ax[1].axhline(highcut, color='orange', linestyle='--')
    ax[0].axvline(t_range[0], color='red', linestyle='--')
    ax[0].axvline(t_range[1], color='orange', linestyle='--')
    ax[1].axvline(t_range[0], color='red', linestyle='--')
    ax[1].axvline(t_range[1], color='orange', linestyle='--')
    ax[0].set_ylabel("Amplitude")
    ax[1].set_ylabel("Frequency (Hz)")
    ax[1].set_title("Original Spectrogram")
    st.pyplot(fig)

    # Filtered waveform å†ç”Ÿå¾©æ´»
    st.markdown("### ãƒ•ã‚£ãƒ«ã‚¿å¾Œã®éŸ³å£°å†ç”Ÿ")
    filtered_buf = io.BytesIO()
    wavfile.write(filtered_buf, rate, filtered_int16)
    filtered_buf.seek(0)
    st.audio(filtered_buf.getvalue(), format="audio/wav")

    # å‘¨æ³¢æ•°è¿½è·¡
    fig2, ax2 = plt.subplots(2, 1, figsize=(12, 6), sharex=True)
    ax2[0].plot(time_f, filtered_int16)
    ax2[0].set_title("Filtered Waveform")
    ax2[0].set_ylabel("Amplitude")

    NFFT, noverlap = 1024, 512
    if cmap == 'monochrome':
        from scipy.signal import spectrogram
        monothre = st.slider("ãƒ¢ãƒã‚¯ãƒ­ç”¨ã—ãã„å€¤ (dB)", -100, 30, -60, step=2)
        freqs, bins, Sxx = spectrogram(filtered_int16, fs=rate, nperseg=NFFT, noverlap=noverlap)
        Sxx_dB = 10 * np.log10(Sxx + 1e-10)
        masked = np.ma.masked_less(Sxx_dB, monothre)
        ax2[1].imshow(masked, aspect='auto', extent=[bins[0], bins[-1], freqs[0], freqs[-1]], origin='lower', cmap='gray_r')
        Pxx = Sxx  # å¾Œç¶šã® max_amps ã‚„ np.argmax ã®ãŸã‚ã«å®šç¾©
    else :
        Pxx, freqs, bins, _ = ax2[1].specgram(filtered_int16, Fs=rate, NFFT=NFFT, noverlap=noverlap, cmap=cmap)
    max_amps = np.max(Pxx, axis=0)
    threshold = threshold_ratio * np.mean(max_amps)
    dominant_raw = np.where(max_amps >= threshold, freqs[np.argmax(Pxx, axis=0)], np.nan)

    time_per_bin = bins[1] - bins[0]
    win_size = max(1, int(smoothing_sec / time_per_bin))
    smoothed_freqs = moving_average(dominant_raw, win_size)

    ax2[1].plot(bins, dominant_raw, color='green', linewidth=1.0, label='Dominant Freq')
    ax2[1].plot(bins, smoothed_freqs, color='red', linewidth=1.5, label='Smoothed Freq')
    ax2[1].set_ylim(lowcut * 0.8, highcut * 1.2)
    ax2[1].set_ylabel("Frequency (Hz)")
    ax2[1].set_xlabel("Time (s)")
    ax2[1].set_title("Filtered Spectrogram")
    ax2[1].legend()
    st.pyplot(fig2)

    # éŸ³éšå¯è¦–åŒ–ï¼ˆfig3ï¼‰
    fig3, ax3 = plt.subplots(figsize=(12, 3))
    midi_pitches = np.array([freq_to_midi(f) if not np.isnan(f) else np.nan for f in smoothed_freqs])
    valid = ~np.isnan(midi_pitches)
    times_valid = bins[valid]
    midi_valid = midi_pitches[valid]
    note_names = [midi_to_note_name(int(round(p))) for p in midi_valid]

    ax3.scatter(times_valid, midi_valid, marker='|', color='blue', s=80)
    unique_midis = sorted(set(int(round(p)) for p in midi_valid))
    ax3.set_yticks(unique_midis)
    ax3.set_yticklabels([midi_to_note_name(p) for p in unique_midis])
    ax3.set_ylim(min(unique_midis) - 2, max(unique_midis) + 2)
    ax3.set_xlabel("Time (s)")
    ax3.set_ylabel("Note")
    ax3.set_title("Detected Notes Over Time")
    ax3.grid(True)
    st.pyplot(fig3)

    # MIDIç”Ÿæˆãƒ»å†ç”Ÿ
    st.markdown("### MIDIç”Ÿæˆãƒ»ä¿å­˜ãƒ»å†ç”Ÿ")
    midi = MIDIFile(1)
    midi.addTempo(0, 0, 120)
    for i, freq in enumerate(smoothed_freqs):
        if np.isnan(freq): continue
        pitch = int(np.round(freq_to_midi(freq)))
        midi.addNote(0, 0, pitch, bins[i], time_per_bin, 100)

    midi_bytes = io.BytesIO()
    midi.writeFile(midi_bytes)
    midi_bytes.seek(0)

    # ç°¡æ˜“WAVç”Ÿæˆï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å†ç”Ÿï¼‰
    midi_audio = generate_wav_from_midi(smoothed_freqs, bins, time_per_bin, rate)
    midi_buf = io.BytesIO()
    wavfile.write(midi_buf, rate, midi_audio)
    midi_buf.seek(0)
    st.audio(midi_buf.getvalue(), format="audio/wav")

    #st.download_button("ğŸµ MIDIãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", midi_bytes.getvalue(), file_name=base_filename + "_midi.mid", mime="audio/midi")

    # ä¿å­˜ç”¨zipä½œæˆ
    raw_buf = io.BytesIO()
    wavfile.write(raw_buf, rate, data)
    raw_buf.seek(0)

    zip_buf = io.BytesIO()
    with zipfile.ZipFile(zip_buf, 'w') as zf:
        zf.writestr(base_filename + '_raw.wav', raw_buf.read())
        zf.writestr(base_filename + '_filtered.wav', filtered_buf.getvalue())
        zf.writestr(base_filename + '_midi.mid', midi_bytes.getvalue())
        zf.writestr(base_filename + '_midi.wav', midi_buf.getvalue())
    zip_buf.seek(0)

    st.download_button("ğŸ“¦ ZIPä¸€æ‹¬ä¿å­˜", zip_buf.getvalue(), file_name=base_filename + ".zip", mime="application/zip")
